请将许可文件并入pypi包中。 Please add the license file to the pypi package.，自定义词典词频计算，发邮件 为什么不能分成 ‘发 v’  和 ‘邮件 n’，某些关键词抽取不到，请问提取关键词时debug信息如何关闭，Maybe the demo site is down?，请问jieba有没有中文纠错的功能呢？，for help,  jython+jieba failed, ValueError: insecure string pickle，fix alllowPos logic in Textrank to be consistent with TF-IDF，jieba/__init__.py 48行，为什么"今天上午"的标注是nr ？，如何给筛选出来的关键词标注词性？，jieba~炖丛从诤未Γ浚可以使用数据库保存用户自定义词典吗？，mac 下 python3 的命令行分词中，选项中加了分割符选项却不指定的话，程序不会自动结束。，ChineseAnalyzer导入失败，offset值应该和原输入保持一致，jython can't use jieba，可否在论文中引用您的分词器，避免含它c的底直诲e`分~，“挺不错” 为什么词性是 i，可否加入情w分析功能? ，词性标注可以只用词性的大类么？，My NLP，HMM模型参数具体是怎样训练出来的？，为什么我用jieba切出来的是一个个的字，而不是词。，自定义词典中单个词语中包含空格和"-"，如何判嘣~後的~，是否有出F在字典?，add self-defined dict of proper nouns from wikipedia (增加wikipediaＳ忻~的dict)，词语是Unicode对词语做文本分析存在的问题，请问一个词有多个词性，自定义字典该如何定义，可以直接对切分语料用baum算法求模型参数吗？，自定义主词库，关闭了HMM，还是会分出英文。无论长短，进行关键词提取之前，能否传入自己的分词结果，关于词语中有空格的情况，［请教］如何将类似“abc123456”的文本切分为“abc”和“123456”？，自定x~典生成，词性标注出的词性与词典中不同，词性标注，Y巴自建~熘腥绾握页鲇锌瞻椎挠⑽慕M合字?，如何用代码修改默认词库？，jieba优化以支持spark-stream高效率分词，词典分隔符用空格就不能添加含有空格的词了，python 无法添加单个词汇，cache文件在分词里起了什么作用？可否有无cache的模式，simplify implementation of 2-gram and 3-gram extraction，jieba.load_userdict()的问题，，开兄控欧拉5555566555555555，mbvcxzzxz/，默认词典有词存疑，wiki自定义词库替代默认词库，有关于词性的吗？，如何在论文中引用结巴分词？，分词结果异常，关键词抽取处理停用词时的一个UE设计问题，添加自定义词典不起作用，是否可以用清华THULAC使用的语料库来训练jieba的模型？，jieba.cut()和jieba.posseg.cut()的分词结果不一致？，在线演示出错了，需要升级，在提取关键词的时候，如何去除掉停止词，如何自定义IDF文件，中英文数字混合切分，结巴分词怎么运行整个文件啊，中文标点符号如何处理？，jieba.load_userdict 可以支持tuple吗？，jieba，jieba.set_dictionary 忽略~性，在一个句子中出现两个相同的组合的词，use jieba in sklearn.feature_extraction.text.TfidfVectorizer，(How) can I permanently change the POS tag for a word?，Efficiency of Jieba python?，    f.name, lineno, line)) ValueError，\行中修改字典，重新load cache，建议词典分隔符空格改成\t，分词的问题，分词错误，用户词典出现错误，你们的demo挂了，jieba.lcut 文件怎么用法，Failed building wheel for jieba，能提供一下统计指定关键词词频的接口吗？，Installation failure，bug in del_word，命令行输入输出的方式，可以标注词性吗，另外问一下jieba可以分句吗？，词性标注的分词和Tokenize分词不一致？，关于TFIDF的几个问题，怎么自动过滤停用词和标点符号?，英文句号的错误，AttributeError: 'module' object has no attribute 'cut'，带逗号的词语切分，IP地址的}，搜索问题，期待Golang版的！，不能删除自定义word，hadoop load userdict，IOError occured when jieba submitted to spark cluster ，tfidf，《》标题符号包围的电影名，电视名能控制直接拆分成一个词吗，jieba0.36，英文单词会被切分，导入词典是报错，第四部分，词性标注的例子出现错误 'pair' object is not iterable，jieba有官方的QQ群之类的吗？，能否对已经分词的文本单独进行词性标注呢，ValueError: math domain error，词性标注的问题，lcut不可用，求助，怎样将某个词必然与其他的词分隔开？，对于jieba分词的一个疑问，想拆除带有特殊符号的词，想拆出一个带有中文和英文的词，带有词性标注的分词效率是多少？，How to use jieba in hadoop?，分词改进，「台中」是被切成「台」「中」，新增自定义词典后分词不准确了，用 pycharm 找不到 cut 怎么回事啊，“我们中出了一个叛徒”分词结果不一致，分词部分报错，是否会出PHP版本的接口？，可以加入HMM模型tran的部分嘛？，求教搜索引擎模式下如何实现词性标注，GAE的支持，能加上分出时间和数字序列吗，用户字典，关键词提取质量很差，添加对 whoosh 的接口